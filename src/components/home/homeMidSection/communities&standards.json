[
  {
    "name": "FAIR",
    "description": "In 2016, the ‘FAIR Guiding Principles for scientific data management and stewardship’ were published in Scientific Data. The authors intended to provide guidelines to improve the Findability, Accessibility, Interoperability, and Reuse of digital assets. The principles emphasise machine-actionability (i.e., the capacity of computational systems to find, access, interoperate, and reuse data with none or minimal human intervention) because humans increasingly rely on computational support to deal with data as a result of the increase in volume, complexity, and creation speed of data.",
    "img_location": "",
    "img_alt": "Chart",
    "learn_more_href": "https://www.go-fair.org/fair-principles/"
  },
  {
    "name": "GA4GH",
    "description": "The Global Alliance for Genomics and Health (GA4GH) is an international, nonprofit alliance formed in 2013 to accelerate the potential of research and medicine to advance human health. Bringing together 600+ leading organizations working in healthcare, research, patient advocacy, life science, and information technology, the GA4GH community is working together to create frameworks and standards to enable the responsible, voluntary, and secure sharing of genomic and health-related data.",
    "img_location": "",
    "img_alt": "Chart",
    "learn_more_href": ""
  },
  {
    "name": "FairSharing",
    "description": "FairSharing is a curated, informative and educational resource on data and metadata standards, inter-related to databases and data policies. FairSharing guides users to discover, select and use these resources with confidence, and encourages producers of resources to make them discoverable, more widely adopted and cited.",
    "img_location": "",
    "img_alt": "Chart",
    "learn_more_href": "https://fairsharing.org/"
  },
  {
    "name": "GSC",
    "description": "The Genomic Standards Consortium (GSC) is an open-membership working body formed in September 2005. The aim of the GSC is making genomic data discoverable. The GSC enables genomic data integration, discovery and comparison through international community-driven standards.",
    "img_location": "",
    "img_alt": "Chart",
    "learn_more_href": "https://gensc.org/"
  },
  {
    "name": "LinkML",
    "description": "LinkML is a flexible modeling language that allows you to author schemas in YAML that describe the structure of your data. Additionally, it is a framework for working with and validating data in a variety of formats (JSON, RDF, TSV), with generators for compiling LinkML schemas to other frameworks.",
    "img_location": "",
    "img_alt": "Chart",
    "learn_more_href": "https://linkml.io/linkml/"
  },
  {
    "name": "MONDO",
    "description": "The Mondo Disease Ontology (Mondo) aims to harmonize disease definitions across the world. The name Mondo comes from the latin word ‘mundus’ and means ‘for the world.’\n\nNumerous sources for disease definitions and data models currently exist, which include HPO, OMIM, SNOMED CT, ICD, PhenoDB, MedDRA, MedGen, ORDO, DO, GARD, etc; however, these sources partially overlap and sometimes conflict, making it difficult to know definitively how they relate to each other. This has resulted in a proliferation of mappings between disease entries in different resources; however mappings are problematic: collectively, they are expensive to create and maintain. Most importantly, the mappings lack completeness, accuracy, and precision; as a result, mapping calls are often inconsistent between resources. The UMLS provides intermediate concepts through which other resources can be mapped, but these mappings suffer from the same challenges: they are not guaranteed to be one-to-one, especially in areas with evolving disease concepts such as rare disease.\n\nIn order to address the lack of a unified disease terminology that provides precise equivalences between disease concepts, we created Mondo, which provides a logic-based structure for unifying multiple disease resources.\n\nMondo’s development is coordinated with the Human Phenotype Ontology (HPO), which describes the individual phenotypic features that constitute a disease. Like the HPO, Mondo provides a hierarchical structure which can be used for classification or “rolling up” diseases to higher level groupings. It provides mappings to other disease resources, but in contrast to other mappings between ontologies, we precisely annotate each mapping using strict semantics, so that we know when two disease names or identifiers are equivalent or one-to-one, in contrast to simply being closely related.",
    "img_location": "",
    "img_alt": "Chart",
    "learn_more_href": "https://mondo.monarchinitiative.org/"
  },
  {
    "name": "SNOMED",
    "description": "Is the most comprehensive, multilingual clinical healthcare terminology in the world.\nIs a resource with comprehensive, scientifically validated clinical content.\nEnables consistent, processable representation of clinical content in electronic health records.\nIs mapped to other international standards.\nIs already used in more than fifty countries.",
    "img_location": "",
    "img_alt": "Chart",
    "learn_more_href": "https://confluence.ihtsdotools.org/display/DOC/SNOMED+CT+Document+Library"
  },
  {
    "name": "HANCESTRO",
    "description": "The Human Ancestry Ontology (HAncestro) provides a systematic description of the ancestry concepts used in the NHGRI-EBI Catalog of published genome-wide association studies. It includes a list of countries, regions and major areas (essentially continents), as well as a fairly exhaustive list of defined ancestral categories, uncategorised ancestral categories and population isolates.",
    "img_location": "",
    "img_alt": "Chart",
    "learn_more_href": "https://github.com/EBISPOT/ancestro"
  },
  {
    "name": "EFO",
    "description": "The Experimental Factor Ontology (EFO) provides a systematic description of many experimental variables available in EBI databases, and for projects such as the GWAS catalog. It combines parts of several biological ontologies, such as UBERON anatomy, ChEBI chemical compounds, and Cell Ontology. The scope of EFO is to support the annotation, analysis and visualization of data handled by many groups at the EBI and as the core ontology for Open Targets. EFO is developed by the EMBL-EBI Samples, Phenotypes and Ontologies Team (SPOT).",
    "img_location": "",
    "img_alt": "Chart",
    "learn_more_href": "https://www.ebi.ac.uk/efo/"
  },
  {
    "name": "HPO",
    "description": "The Human Phenotype Ontology (HPO) provides a standardized vocabulary of phenotypic abnormalities encountered in human disease. Each term in the HPO describes a phenotypic abnormality, such as Atrial septal defect. The HPO is currently being developed using the medical literature, Orphanet, DECIPHER, and OMIM. HPO currently contains over 13,000 terms and over 156,000 annotations to hereditary diseases. The HPO project and others have developed software for phenotype-driven differential diagnostics, genomic diagnostics, and translational research. The HPO is a flagship product of the Monarch Initiative, an NIH-supported international consortium dedicated to semantic integration of biomedical and model organism data with the ultimate goal of improving biomedical research. The HPO, as a part of the Monarch Initiative, is a central component of one of the 13 driver projects in the Global Alliance for Genomics and Health (GA4GH) strategic roadmap.",
    "img_location": "",
    "img_alt": "Chart",
    "learn_more_href": "https://hpo.jax.org/app/"
  },
  {
    "name": "UBERON",
    "description": "Uberon is an integrated cross-species anatomy ontology representing a variety of entities classified according to traditional anatomical criteria such as structure, function and developmental lineage. The ontology includes comprehensive relationships to taxon-specific anatomical ontologies, allowing integration of functional, phenotype and expression data.",
    "img_location": "",
    "img_alt": "Chart",
    "learn_more_href": "https://www.ebi.ac.uk/ols/ontologies/uberon"
  },
  {
    "name": "NAKO",
    "description": "The German National Cohort (“NAKO Gesundheitsstudie”) is an interdisciplinary, population-based cohort study that will follow the long-term medical histories of 200,000 participants over 25-30 years. As Germany’s largest health study, the overarching aim of the National Cohort is to inform more effective disease prevention strategies, with a focus on seven major disease groups: cancer, diabetes, and cardiovascular, neurologic and psychiatric, infectious, respiratory and musculoskeletal diseases. It will provide a major, central resource for population-based epidemiology in Germany, and will help to identify new and tailored strategies for early detection, prediction, and primary prevention of major diseases.",
    "img_location": "",
    "img_alt": "Chart",
    "learn_more_href": ""
  },
  {
    "name": "NCT-MASTER",
    "description": "The NCT and DKTK MASTER (Molecularly Aided Stratification for Tumor Eradication) Program is a central platform for comprehensive, multidimensional characterization of young cancer patients and patients with rare cancers seen at NCT/UCC Dresden, NCT Heidelberg, or one of the sites of the German Cancer Consortium (DKTK; Berlin, Essen/Düsseldorf, Frankfurt/Mainz, Freiburg, Munich, Tübingen)",
    "img_location": "",
    "img_alt": "Chart",
    "learn_more_href": "https://www.nct-heidelberg.de/forschung/molecular-stratification/master.html"
  },
  {
    "name": "INFORM",
    "description": "INFORM (INdividualized Therapy FOr Relapsed Malignancies in Childhood) takes on the challenge of offering these patients a second chance. It is the largest transnational genome sequencing program for children with cancer in Europe, making it possible to identify molecular targets that may open up new treatment options. Since 2015, many children and adolescents have been either included in clinical trials after having their genome decoded in INFORM, or have been given so-called off-label treatment under controlled conditions with drugs that were originally approved for adults. Up to now, more than 1,800 patients have been included in the INFORM registry. The results of INFORM are also used to develop innovative phase I/II studies such as the INFORM2 trial series.",
    "img_location": "",
    "img_alt": "Chart",
    "learn_more_href": "https://www.kitz-heidelberg.de/en/clinical-studies/molecular-diagnostics-studies/inform/"
  },
  {
    "name": "DKTK",
    "description": "In the German Consortium for Translational Cancer Research, researchers and physicians at eight locations in Germany are cooperating to bring promising approaches in cancer research into clinical practice more quickly.",
    "img_location": "",
    "img_alt": "Chart",
    "learn_more_href": "https://dktk.dkfz.de/"
  },
  {
    "name": "DZHK",
    "description": "The German Center for Cardiovascular Research DZHK, founded in 2011, unites basic and clinical researchers at seven locations in Germany. The aim of the facility is to bring new approaches from cardiovascular research into clinical application as quickly as possible in order to improve the prevention, diagnosis and treatment of cardiovascular diseases.",
    "img_location": "",
    "img_alt": "Chart",
    "learn_more_href": "https://dzhk.de/das-dzhk/ueber-uns/mission/"
  },
  {
    "name": "MII",
    "description": "Medical Informatics Initiative Core Dataset. The consortia of the Medical Informatics Initiative (MII) and all participating university hospital sites have agreed upon a common set of core data. This is based on international IT and terminology standards, and is the prerequisite for shared use of data. Within the MII’s corresponding working groups, the university hospital sites across all consortia defined what data records must, at a minimum, be captured and stored by the MII’s data integration centres for all in-patients – independent of medical indication and of each consortium’s specific use case. This guarantees interoperability between data integration centres despite their diverse underlying concepts.",
    "img_location": "",
    "img_alt": "Chart",
    "learn_more_href": "https://www.medizininformatik-initiative.de/en/medical-informatics-initiatives-core-data-set"
  },
  {
    "name": "DUO",
    "description": "Data Use Ontology (DUO) is a standard released by the fEGA, which grants researchers the ability to use human biomedical datasets for controlled-access datasets depending on their research purpose and permissions. Users can tag the datasets with specific usage constraints, which allows them to be discovered based on the permissions granted to health, clinical, and biological researchers. The DUO standard has already been used to annotate over 200,000 datasets throughout the world. For instance, a rare disease researcher can access any dataset that is authorized for commercial and rare disease use cases. The DUO standard contains human-readable explanations and terms, generated by the corresponding data access committees (DAC). The DUO standard is structured with 25 terms that reflect two types of data use: permission and modifier terms. Permission terms contain, for instance: general research use (GRU), health or medical or biomedical (HMB) disease-specific (DS), and population origins or ancestry (POA), which are all clearly approved applications or specialized fields of study. Modifier terms include limitations and requirements within controlled access such as non-commercial use only (NCU), ethics approval required (IRB) and genetics studies only (GSO).",
    "img_location": "",
    "img_alt": "Chart",
    "learn_more_href": ""
  },
  {
    "name": "DRS",
    "description": "The Data Repository Service (DRS) API is a standard released by GA4GH in 2019. It provides standardized access to data independent from the architecture or technology stack of the storage repository. It essentially acts as a data catalog that lists access metadata in a standardized way. Another GA4GH standard being used by GHGA is the encryption file format Crypt4GH. It acts as a container around existing file formats, encrypting files with a symmetric stream cipher to allow for random access of the encrypted data. The symmetric key is encrypted separately via asynchronous encryption. Ideally, this means that neither the secret nor the data itself will be stored on a disk in a decrypted state throughout the file life cycle. Crypt4GH thus provides a solution to both encryptions at rest as well as transfer encryption. It is meant as a file format for bioinformatics research, but in theory can be used for any kind of file format, and some bioinformatic toolsets, like SAMtools, already provide support for Crypt4GH.",
    "img_location": "",
    "img_alt": "Chart",
    "learn_more_href": ""
  },
  {
    "name": "MI Standards",
    "description": "Minimum information (MI) standards are sets of guidelines and formats for reporting data derived by specific high-throughput methods. The purpose of MI standards is to ensure the data generated by high-throughput methods can be easily verified, analyzed and interpreted by the wider scientific community. Minimal information standards are available for a vast variety of experiment types including microarray (MIAME), RNAseq (MINSEQE), metabolomics (MSI) and proteomics (MIAPE).",
    "img_location": "",
    "img_alt": "Chart",
    "learn_more_href": "https://www.ebi.ac.uk/training/online/courses/bioinformatics-terrified/what-makes-a-good-bioinformatics-database/minimum-information-standards/#:~:text=Minimum%20information%20standards%20are%20sets,by%20the%20wider%20scientific%20community."
  },
  {
    "name": "DublinCore",
    "description": "The Dublin CoreTM Metadata Element Set is a vocabulary of fifteen properties for use in resource description. The fifteen element \"Dublin CoreTM\" described in this standard is part of a larger set of metadata vocabularies and technical specifications maintained by the Dublin CoreTM Metadata Initiative (DCMI). The full set of vocabularies, DCMI Metadata Terms [DCMI-TERMS], also includes sets of resource classes (including the DCMI Type Vocabulary [DCMI-TYPE]), vocabulary encoding schemes, and syntax encoding schemes. The terms in DCMI vocabularies are intended to be used in combination with terms from other, compatible vocabularies in the context of application profiles and on the basis of the DCMI Abstract Model [DCAM].",
    "img_location": "",
    "img_alt": "Chart",
    "learn_more_href": ""
  }
]
